{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#하이퍼파라미터-세팅-및-seed-고정\" data-toc-modified-id=\"하이퍼파라미터-세팅-및-seed-고정-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>하이퍼파라미터 세팅 및 seed 고정</a></span></li><li><span><a href=\"#학습-데이터-EDA\" data-toc-modified-id=\"학습-데이터-EDA-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>학습 데이터 EDA</a></span></li><li><span><a href=\"#데이터-전처리-함수-정의-(Dataset)\" data-toc-modified-id=\"데이터-전처리-함수-정의-(Dataset)-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>데이터 전처리 함수 정의 (Dataset)</a></span></li><li><span><a href=\"#Dataset-정의-및-DataLoader-할당\" data-toc-modified-id=\"Dataset-정의-및-DataLoader-할당-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Dataset 정의 및 DataLoader 할당</a></span><ul class=\"toc-item\"><li><span><a href=\"#데이터-샘플-시각화-(Show-example-image-and-mask)\" data-toc-modified-id=\"데이터-샘플-시각화-(Show-example-image-and-mask)-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>데이터 샘플 시각화 (Show example image and mask)</a></span></li></ul></li><li><span><a href=\"#baseline-model\" data-toc-modified-id=\"baseline-model-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>baseline model</a></span><ul class=\"toc-item\"><li><span><a href=\"#UNet-with-efficientnet-model\" data-toc-modified-id=\"UNet-with-efficientnet-model-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>UNet with efficientnet model</a></span></li></ul></li><li><span><a href=\"#train,-validation,-test-함수-정의\" data-toc-modified-id=\"train,-validation,-test-함수-정의-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>train, validation, test 함수 정의</a></span></li><li><span><a href=\"#모델-저장-함수-정의\" data-toc-modified-id=\"모델-저장-함수-정의-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>모델 저장 함수 정의</a></span></li><li><span><a href=\"#모델-생성-및-Loss-function,-Optimizer-정의\" data-toc-modified-id=\"모델-생성-및-Loss-function,-Optimizer-정의-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>모델 생성 및 Loss function, Optimizer 정의</a></span></li><li><span><a href=\"#저장된-model-불러오기-(학습된-이후)\" data-toc-modified-id=\"저장된-model-불러오기-(학습된-이후)-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>저장된 model 불러오기 (학습된 이후)</a></span></li><li><span><a href=\"#submission을-위한-test-함수-정의\" data-toc-modified-id=\"submission을-위한-test-함수-정의-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>submission을 위한 test 함수 정의</a></span></li><li><span><a href=\"#submission.csv-생성\" data-toc-modified-id=\"submission.csv-생성-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>submission.csv 생성</a></span></li><li><span><a href=\"#Reference\" data-toc-modified-id=\"Reference-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Reference</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:36.739754Z",
     "start_time": "2021-04-29T13:07:34.201640Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'label_accuracy_score' from 'utils' (/opt/ml/p3-ims-obd-garbagecollector/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-14972560cf19>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlabel_accuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'label_accuracy_score' from 'utils' (/opt/ml/p3-ims-obd-garbagecollector/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from utils import label_accuracy_score\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# 전처리를 위한 라이브러리\n",
    "from pycocotools.coco import COCO\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "# 시각화를 위한 라이브러리\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "plt.rcParams['axes.grid'] = False\n",
    "\n",
    "print('pytorch version: {}'.format(torch.__version__))\n",
    "print('GPU 사용 가능 여부: {}'.format(torch.cuda.is_available()))\n",
    "\n",
    "print(torch.cuda.get_device_name(0))\n",
    "print(torch.cuda.device_count())\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"   # GPU 사용 가능 여부에 따라 device 정보 저장"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 하이퍼파라미터 세팅 및 seed 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:38.898161Z",
     "start_time": "2021-04-29T13:07:38.892162Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 8   # Mini-batch size\n",
    "num_epochs = 20\n",
    "learning_rate = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:39.277417Z",
     "start_time": "2021-04-29T13:07:39.267417Z"
    }
   },
   "outputs": [],
   "source": [
    "# seed 고정\n",
    "random_seed = 21\n",
    "torch.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "# torch.cuda.manual_seed_all(random_seed) # if use multi-GPU\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(random_seed)\n",
    "random.seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 학습 데이터 EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:43.948820Z",
     "start_time": "2021-04-29T13:07:40.177883Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "dataset_path = '../input/data'\n",
    "anns_file_path = dataset_path + '/' + 'train.json'\n",
    "\n",
    "# Read annotations\n",
    "with open(anns_file_path, 'r') as f:\n",
    "    dataset = json.loads(f.read())\n",
    "\n",
    "categories = dataset['categories']\n",
    "anns = dataset['annotations']\n",
    "imgs = dataset['images']\n",
    "nr_cats = len(categories)\n",
    "nr_annotations = len(anns)\n",
    "nr_images = len(imgs)\n",
    "\n",
    "# Load categories and super categories\n",
    "cat_names = []\n",
    "super_cat_names = []\n",
    "super_cat_ids = {}\n",
    "super_cat_last_name = ''\n",
    "nr_super_cats = 0\n",
    "for cat_it in categories:\n",
    "    cat_names.append(cat_it['name'])\n",
    "    super_cat_name = cat_it['supercategory']\n",
    "    # Adding new supercat\n",
    "    if super_cat_name != super_cat_last_name:\n",
    "        super_cat_names.append(super_cat_name)\n",
    "        super_cat_ids[super_cat_name] = nr_super_cats\n",
    "        super_cat_last_name = super_cat_name\n",
    "        nr_super_cats += 1\n",
    "\n",
    "print('Number of super categories:', nr_super_cats)\n",
    "print('Number of categories:', nr_cats)\n",
    "print('Number of annotations:', nr_annotations)\n",
    "print('Number of images:', nr_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:44.203818Z",
     "start_time": "2021-04-29T13:07:43.949794Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Count annotations\n",
    "cat_histogram = np.zeros(nr_cats,dtype=int)\n",
    "for ann in anns:\n",
    "    cat_histogram[ann['category_id']] += 1\n",
    "\n",
    "# Initialize the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "# Convert to DataFrame\n",
    "df = pd.DataFrame({'Categories': cat_names, 'Number of annotations': cat_histogram})\n",
    "df = df.sort_values('Number of annotations', 0, False)\n",
    "\n",
    "# Plot the histogram\n",
    "plt.title(\"category distribution of train set \")\n",
    "plot_1 = sns.barplot(x=\"Number of annotations\", y=\"Categories\", data=df, label=\"Total\", color=\"b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:44.219399Z",
     "start_time": "2021-04-29T13:07:44.204793Z"
    }
   },
   "outputs": [],
   "source": [
    "# category labeling \n",
    "sorted_temp_df = df.sort_index()\n",
    "\n",
    "# background = 0 에 해당되는 label 추가 후 기존들을 모두 label + 1 로 설정\n",
    "sorted_df = pd.DataFrame([\"Backgroud\"], columns = [\"Categories\"])\n",
    "sorted_df = sorted_df.append(sorted_temp_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:44.234403Z",
     "start_time": "2021-04-29T13:07:44.221292Z"
    }
   },
   "outputs": [],
   "source": [
    "# class (Categories) 에 따른 index 확인 (0~11 : 총 12개)\n",
    "sorted_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 데이터 전처리 함수 정의 (Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:44.249897Z",
     "start_time": "2021-04-29T13:07:44.235338Z"
    }
   },
   "outputs": [],
   "source": [
    "category_names = list(sorted_df.Categories)\n",
    "\n",
    "def get_classname(classID, cats):\n",
    "    for i in range(len(cats)):\n",
    "        if cats[i]['id']==classID:\n",
    "            return cats[i]['name']\n",
    "    return \"None\"\n",
    "\n",
    "class CustomDataLoader(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, data_dir, mode = 'train', transform = None):\n",
    "        super().__init__()\n",
    "        self.mode = mode\n",
    "        self.transform = transform\n",
    "        self.coco = COCO(data_dir)\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        # dataset이 index되어 list처럼 동작\n",
    "        image_id = self.coco.getImgIds(imgIds=index)\n",
    "        image_infos = self.coco.loadImgs(image_id)[0]\n",
    "\n",
    "        # cv2 를 활용하여 image 불러오기\n",
    "        images = cv2.imread(os.path.join(dataset_path, image_infos['file_name']))\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        \n",
    "        if (self.mode in ('train', 'val')):\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "            # print(\"image_infos['id'] : {}\".format(image_infos['id']) )\n",
    "            # Load the categories in a variable\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "\n",
    "            # masks : size가 (height x width)인 2D\n",
    "            # 각각의 pixel 값에는 \"category id + 1\" 할당\n",
    "            # Background = 0\n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            # Unknown = 1, General trash = 2, ... , Cigarette = 11\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)\n",
    "            masks = masks.astype(np.float32)\n",
    "\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images, mask=masks)\n",
    "                images = transformed[\"image\"]\n",
    "                masks = transformed[\"mask\"]\n",
    "            \n",
    "            return images, masks, image_infos\n",
    "        \n",
    "        if self.mode == 'test':\n",
    "            # transform -> albumentations 라이브러리 활용\n",
    "            if self.transform is not None:\n",
    "                transformed = self.transform(image=images)\n",
    "                images = transformed[\"image\"]\n",
    "            \n",
    "            return images, image_infos\n",
    "    \n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        # 전체 dataset의 size를 return\n",
    "        return len(self.coco.getImgIds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 정의 및 DataLoader 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:49.065085Z",
     "start_time": "2021-04-29T13:07:44.250899Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train.json / validation.json / test.json 디렉토리 설정\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "# collate_fn needs for batch\n",
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_transform = A.Compose([\n",
    "                            ToTensorV2()\n",
    "                            ])\n",
    "\n",
    "val_transform = A.Compose([\n",
    "                          ToTensorV2()\n",
    "                          ])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "                           ToTensorV2()\n",
    "                           ])\n",
    "\n",
    "# create own Dataset 1 (skip)\n",
    "# validation set을 직접 나누고 싶은 경우\n",
    "# train_all_path = '../input/data/train_all.json'\n",
    "# e.g. random_split 사용하여 data set을 8:2 로 분할\n",
    "# train_size = int(0.8*len(dataset))\n",
    "# val_size = int(len(dataset)-train_size)\n",
    "# dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=transform)\n",
    "# train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# create own Dataset 2\n",
    "# train dataset\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "\n",
    "# validation dataset\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=val_transform)\n",
    "\n",
    "# test dataset\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "\n",
    "# DataLoader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=4,\n",
    "                                           collate_fn=collate_fn)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, \n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         num_workers=4,\n",
    "                                         collate_fn=collate_fn)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          num_workers=4,\n",
    "                                          collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 데이터 샘플 시각화 (Show example image and mask)\n",
    "\n",
    "- `train_loader` \n",
    "- `val_loader` \n",
    "- `test_loader` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:49.560920Z",
     "start_time": "2021-04-29T13:07:49.066121Z"
    }
   },
   "outputs": [],
   "source": [
    "# train_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in train_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:50.071221Z",
     "start_time": "2021-04-29T13:07:49.561812Z"
    }
   },
   "outputs": [],
   "source": [
    "# val_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, masks, image_infos in val_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(12, 12))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "print('mask shape: ', list(temp_masks[0].shape))\n",
    "\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(temp_masks[0]))])\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "ax2.imshow(temp_masks[0])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"masks : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:07:50.326221Z",
     "start_time": "2021-04-29T13:07:50.072194Z"
    }
   },
   "outputs": [],
   "source": [
    "# test_loader의 output 결과(image 및 mask) 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos[0]\n",
    "    temp_images = imgs\n",
    "    # temp_masks = masks\n",
    "    \n",
    "    break\n",
    "\n",
    "fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=(6, 6))\n",
    "\n",
    "print('image shape:', list(temp_images[0].shape))\n",
    "\n",
    "ax1.imshow(temp_images[0].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"input image : {}\".format(image_infos['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## baseline model\n",
    "\n",
    "### UNet with efficientnet model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:09:11.153931Z",
     "start_time": "2021-04-29T13:09:09.447631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 128, 128]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 128, 128]             128\n",
      "              ReLU-3         [-1, 64, 128, 128]               0\n",
      "         MaxPool2d-4           [-1, 64, 64, 64]               0\n",
      "            Conv2d-5          [-1, 128, 64, 64]           8,192\n",
      "       BatchNorm2d-6          [-1, 128, 64, 64]             256\n",
      "              ReLU-7          [-1, 128, 64, 64]               0\n",
      "            Conv2d-8          [-1, 128, 64, 64]           4,608\n",
      "       BatchNorm2d-9          [-1, 128, 64, 64]             256\n",
      "             ReLU-10          [-1, 128, 64, 64]               0\n",
      "           Conv2d-11          [-1, 256, 64, 64]          32,768\n",
      "      BatchNorm2d-12          [-1, 256, 64, 64]             512\n",
      "           Conv2d-13          [-1, 256, 64, 64]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 64, 64]             512\n",
      "             ReLU-15          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-16          [-1, 256, 64, 64]               0\n",
      "           Conv2d-17          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-18          [-1, 128, 64, 64]             256\n",
      "             ReLU-19          [-1, 128, 64, 64]               0\n",
      "           Conv2d-20          [-1, 128, 64, 64]           4,608\n",
      "      BatchNorm2d-21          [-1, 128, 64, 64]             256\n",
      "             ReLU-22          [-1, 128, 64, 64]               0\n",
      "           Conv2d-23          [-1, 256, 64, 64]          32,768\n",
      "      BatchNorm2d-24          [-1, 256, 64, 64]             512\n",
      "             ReLU-25          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-26          [-1, 256, 64, 64]               0\n",
      "           Conv2d-27          [-1, 128, 64, 64]          32,768\n",
      "      BatchNorm2d-28          [-1, 128, 64, 64]             256\n",
      "             ReLU-29          [-1, 128, 64, 64]               0\n",
      "           Conv2d-30          [-1, 128, 64, 64]           4,608\n",
      "      BatchNorm2d-31          [-1, 128, 64, 64]             256\n",
      "             ReLU-32          [-1, 128, 64, 64]               0\n",
      "           Conv2d-33          [-1, 256, 64, 64]          32,768\n",
      "      BatchNorm2d-34          [-1, 256, 64, 64]             512\n",
      "             ReLU-35          [-1, 256, 64, 64]               0\n",
      "       Bottleneck-36          [-1, 256, 64, 64]               0\n",
      "           Conv2d-37          [-1, 256, 64, 64]          65,536\n",
      "      BatchNorm2d-38          [-1, 256, 64, 64]             512\n",
      "             ReLU-39          [-1, 256, 64, 64]               0\n",
      "           Conv2d-40          [-1, 256, 32, 32]          18,432\n",
      "      BatchNorm2d-41          [-1, 256, 32, 32]             512\n",
      "             ReLU-42          [-1, 256, 32, 32]               0\n",
      "           Conv2d-43          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-44          [-1, 512, 32, 32]           1,024\n",
      "           Conv2d-45          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-47          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-48          [-1, 512, 32, 32]               0\n",
      "           Conv2d-49          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-50          [-1, 256, 32, 32]             512\n",
      "             ReLU-51          [-1, 256, 32, 32]               0\n",
      "           Conv2d-52          [-1, 256, 32, 32]          18,432\n",
      "      BatchNorm2d-53          [-1, 256, 32, 32]             512\n",
      "             ReLU-54          [-1, 256, 32, 32]               0\n",
      "           Conv2d-55          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-56          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-57          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-58          [-1, 512, 32, 32]               0\n",
      "           Conv2d-59          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-60          [-1, 256, 32, 32]             512\n",
      "             ReLU-61          [-1, 256, 32, 32]               0\n",
      "           Conv2d-62          [-1, 256, 32, 32]          18,432\n",
      "      BatchNorm2d-63          [-1, 256, 32, 32]             512\n",
      "             ReLU-64          [-1, 256, 32, 32]               0\n",
      "           Conv2d-65          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-66          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-67          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-68          [-1, 512, 32, 32]               0\n",
      "           Conv2d-69          [-1, 256, 32, 32]         131,072\n",
      "      BatchNorm2d-70          [-1, 256, 32, 32]             512\n",
      "             ReLU-71          [-1, 256, 32, 32]               0\n",
      "           Conv2d-72          [-1, 256, 32, 32]          18,432\n",
      "      BatchNorm2d-73          [-1, 256, 32, 32]             512\n",
      "             ReLU-74          [-1, 256, 32, 32]               0\n",
      "           Conv2d-75          [-1, 512, 32, 32]         131,072\n",
      "      BatchNorm2d-76          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-77          [-1, 512, 32, 32]               0\n",
      "       Bottleneck-78          [-1, 512, 32, 32]               0\n",
      "           Conv2d-79          [-1, 512, 32, 32]         262,144\n",
      "      BatchNorm2d-80          [-1, 512, 32, 32]           1,024\n",
      "             ReLU-81          [-1, 512, 32, 32]               0\n",
      "           Conv2d-82          [-1, 512, 16, 16]          73,728\n",
      "      BatchNorm2d-83          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-84          [-1, 512, 16, 16]               0\n",
      "           Conv2d-85         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-86         [-1, 1024, 16, 16]           2,048\n",
      "           Conv2d-87         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-89         [-1, 1024, 16, 16]               0\n",
      "       Bottleneck-90         [-1, 1024, 16, 16]               0\n",
      "           Conv2d-91          [-1, 512, 16, 16]         524,288\n",
      "      BatchNorm2d-92          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-93          [-1, 512, 16, 16]               0\n",
      "           Conv2d-94          [-1, 512, 16, 16]          73,728\n",
      "      BatchNorm2d-95          [-1, 512, 16, 16]           1,024\n",
      "             ReLU-96          [-1, 512, 16, 16]               0\n",
      "           Conv2d-97         [-1, 1024, 16, 16]         524,288\n",
      "      BatchNorm2d-98         [-1, 1024, 16, 16]           2,048\n",
      "             ReLU-99         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-100         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-101          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-102          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-103          [-1, 512, 16, 16]               0\n",
      "          Conv2d-104          [-1, 512, 16, 16]          73,728\n",
      "     BatchNorm2d-105          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-106          [-1, 512, 16, 16]               0\n",
      "          Conv2d-107         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-108         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-109         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-110         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-111          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-112          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-113          [-1, 512, 16, 16]               0\n",
      "          Conv2d-114          [-1, 512, 16, 16]          73,728\n",
      "     BatchNorm2d-115          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-116          [-1, 512, 16, 16]               0\n",
      "          Conv2d-117         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-118         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-119         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-120         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-121          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-122          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-123          [-1, 512, 16, 16]               0\n",
      "          Conv2d-124          [-1, 512, 16, 16]          73,728\n",
      "     BatchNorm2d-125          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-126          [-1, 512, 16, 16]               0\n",
      "          Conv2d-127         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-129         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-130         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-131          [-1, 512, 16, 16]         524,288\n",
      "     BatchNorm2d-132          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-133          [-1, 512, 16, 16]               0\n",
      "          Conv2d-134          [-1, 512, 16, 16]          73,728\n",
      "     BatchNorm2d-135          [-1, 512, 16, 16]           1,024\n",
      "            ReLU-136          [-1, 512, 16, 16]               0\n",
      "          Conv2d-137         [-1, 1024, 16, 16]         524,288\n",
      "     BatchNorm2d-138         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-139         [-1, 1024, 16, 16]               0\n",
      "      Bottleneck-140         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-141         [-1, 1024, 16, 16]       1,048,576\n",
      "     BatchNorm2d-142         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-143         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-144         [-1, 1024, 16, 16]         294,912\n",
      "     BatchNorm2d-145         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-146         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-147         [-1, 2048, 16, 16]       2,097,152\n",
      "     BatchNorm2d-148         [-1, 2048, 16, 16]           4,096\n",
      "          Conv2d-149         [-1, 2048, 16, 16]       2,097,152\n",
      "     BatchNorm2d-150         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-151         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-152         [-1, 2048, 16, 16]               0\n",
      "          Conv2d-153         [-1, 1024, 16, 16]       2,097,152\n",
      "     BatchNorm2d-154         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-155         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-156         [-1, 1024, 16, 16]         294,912\n",
      "     BatchNorm2d-157         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-158         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-159         [-1, 2048, 16, 16]       2,097,152\n",
      "     BatchNorm2d-160         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-161         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-162         [-1, 2048, 16, 16]               0\n",
      "          Conv2d-163         [-1, 1024, 16, 16]       2,097,152\n",
      "     BatchNorm2d-164         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-165         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-166         [-1, 1024, 16, 16]         294,912\n",
      "     BatchNorm2d-167         [-1, 1024, 16, 16]           2,048\n",
      "            ReLU-168         [-1, 1024, 16, 16]               0\n",
      "          Conv2d-169         [-1, 2048, 16, 16]       2,097,152\n",
      "     BatchNorm2d-170         [-1, 2048, 16, 16]           4,096\n",
      "            ReLU-171         [-1, 2048, 16, 16]               0\n",
      "      Bottleneck-172         [-1, 2048, 16, 16]               0\n",
      "   ResNetEncoder-173  [[-1, 3, 256, 256], [-1, 64, 128, 128], [-1, 256, 64, 64], [-1, 512, 32, 32], [-1, 1024, 16, 16], [-1, 2048, 16, 16]]               0\n",
      "          Conv2d-174          [-1, 256, 16, 16]         524,288\n",
      "     BatchNorm2d-175          [-1, 256, 16, 16]             512\n",
      "            ReLU-176          [-1, 256, 16, 16]               0\n",
      "          Conv2d-177         [-1, 2048, 16, 16]          18,432\n",
      "          Conv2d-178          [-1, 256, 16, 16]         524,288\n",
      "     BatchNorm2d-179          [-1, 256, 16, 16]             512\n",
      "            ReLU-180          [-1, 256, 16, 16]               0\n",
      "          Conv2d-181         [-1, 2048, 16, 16]          18,432\n",
      "          Conv2d-182          [-1, 256, 16, 16]         524,288\n",
      "     BatchNorm2d-183          [-1, 256, 16, 16]             512\n",
      "            ReLU-184          [-1, 256, 16, 16]               0\n",
      "          Conv2d-185         [-1, 2048, 16, 16]          18,432\n",
      "          Conv2d-186          [-1, 256, 16, 16]         524,288\n",
      "     BatchNorm2d-187          [-1, 256, 16, 16]             512\n",
      "            ReLU-188          [-1, 256, 16, 16]               0\n",
      "AdaptiveAvgPool2d-189           [-1, 2048, 1, 1]               0\n",
      "          Conv2d-190            [-1, 256, 1, 1]         524,288\n",
      "     BatchNorm2d-191            [-1, 256, 1, 1]             512\n",
      "            ReLU-192            [-1, 256, 1, 1]               0\n",
      "          Conv2d-193          [-1, 256, 16, 16]         327,680\n",
      "     BatchNorm2d-194          [-1, 256, 16, 16]             512\n",
      "            ReLU-195          [-1, 256, 16, 16]               0\n",
      "         Dropout-196          [-1, 256, 16, 16]               0\n",
      "            ASPP-197          [-1, 256, 16, 16]               0\n",
      "          Conv2d-198          [-1, 256, 16, 16]           2,304\n",
      "          Conv2d-199          [-1, 256, 16, 16]          65,536\n",
      "     BatchNorm2d-200          [-1, 256, 16, 16]             512\n",
      "            ReLU-201          [-1, 256, 16, 16]               0\n",
      "UpsamplingBilinear2d-202          [-1, 256, 64, 64]               0\n",
      "          Conv2d-203           [-1, 48, 64, 64]          12,288\n",
      "     BatchNorm2d-204           [-1, 48, 64, 64]              96\n",
      "            ReLU-205           [-1, 48, 64, 64]               0\n",
      "          Conv2d-206          [-1, 304, 64, 64]           2,736\n",
      "          Conv2d-207          [-1, 256, 64, 64]          77,824\n",
      "     BatchNorm2d-208          [-1, 256, 64, 64]             512\n",
      "            ReLU-209          [-1, 256, 64, 64]               0\n",
      "DeepLabV3PlusDecoder-210          [-1, 256, 64, 64]               0\n",
      "          Conv2d-211           [-1, 12, 64, 64]           3,084\n",
      "UpsamplingBilinear2d-212         [-1, 12, 256, 256]               0\n",
      "        Identity-213         [-1, 12, 256, 256]               0\n",
      "      Activation-214         [-1, 12, 256, 256]               0\n",
      "================================================================\n",
      "Total params: 26,152,284\n",
      "Trainable params: 26,152,284\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.75\n",
      "Forward/backward pass size (MB): 631.90\n",
      "Params size (MB): 99.76\n",
      "Estimated Total Size (MB): 732.41\n",
      "----------------------------------------------------------------\n",
      "None\n",
      "DeepLabV3Plus(\n",
      "  (encoder): ResNetEncoder(\n",
      "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "    (layer1): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer2): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer3): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (3): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (4): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (5): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (layer4): Sequential(\n",
      "      (0): Bottleneck(\n",
      "        (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "        (downsample): Sequential(\n",
      "          (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "          (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        )\n",
      "      )\n",
      "      (1): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "      (2): Bottleneck(\n",
      "        (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), groups=32, bias=False)\n",
      "        (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), dilation=(2, 2), bias=False)\n",
      "        (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (relu): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (decoder): DeepLabV3PlusDecoder(\n",
      "    (aspp): Sequential(\n",
      "      (0): ASPP(\n",
      "        (convs): ModuleList(\n",
      "          (0): Sequential(\n",
      "            (0): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (1): ASPPSeparableConv(\n",
      "            (0): SeparableConv2d(\n",
      "              (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(12, 12), dilation=(12, 12), groups=2048, bias=False)\n",
      "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (2): ASPPSeparableConv(\n",
      "            (0): SeparableConv2d(\n",
      "              (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(24, 24), dilation=(24, 24), groups=2048, bias=False)\n",
      "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (3): ASPPSeparableConv(\n",
      "            (0): SeparableConv2d(\n",
      "              (0): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(36, 36), dilation=(36, 36), groups=2048, bias=False)\n",
      "              (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            )\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU()\n",
      "          )\n",
      "          (4): ASPPPooling(\n",
      "            (0): AdaptiveAvgPool2d(output_size=1)\n",
      "            (1): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "            (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (3): ReLU()\n",
      "          )\n",
      "        )\n",
      "        (project): Sequential(\n",
      "          (0): Conv2d(1280, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU()\n",
      "          (3): Dropout(p=0.5, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (1): SeparableConv2d(\n",
      "        (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256, bias=False)\n",
      "        (1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "    (up): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n",
      "    (block1): Sequential(\n",
      "      (0): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "    (block2): Sequential(\n",
      "      (0): SeparableConv2d(\n",
      "        (0): Conv2d(304, 304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=304, bias=False)\n",
      "        (1): Conv2d(304, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (segmentation_head): SegmentationHead(\n",
      "    (0): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): UpsamplingBilinear2d(scale_factor=4.0, mode=bilinear)\n",
      "    (2): Activation(\n",
      "      (activation): Identity()\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# jupyter command 에서 library download\n",
    "# !pip install git+https://github.com/qubvel/segmentation_models.pytorch\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "import torch\n",
    "import timm\n",
    "#from pytorch_model_summary import summary\n",
    "from unet import UNet3Plus, UNet3Plus_DeepSup, UNet3Plus_DeepSup_CGM\n",
    "from torchsummary import summary\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "import numpy as np\n",
    "# model 불러오기\n",
    "# 출력 레이블 수 정의 (classes = 12)\n",
    "#model = smp.Unet(encoder_name='efficientnet-b0', classes=12 , encoder_weights=\"imagenet\", activation=None)\n",
    "# model = model.to(device)\n",
    "#print(summary(model, (3, 256, 256), device='cpu'))\n",
    "\n",
    "\n",
    "\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name='resnext50_32x4d',\n",
    "    encoder_weights='swsl',\n",
    "    encoder_output_stride=16,\n",
    "#     decoder_atrous_rates=(6, 12, 18),\n",
    "    classes=12\n",
    ")\n",
    "print(summary(model, (3, 256, 256), device='cpu'))\n",
    "print(model)\n",
    "\n",
    "\n",
    "# model = timm.create_model('resnest50d', pretrained=False)\n",
    "# print(summary(model, torch.zeros(1, 3, 320, 320), show_input=False))\n",
    "# print(model)\n",
    "#model = UNet3Plus(n_channels=3, n_classes=12)\n",
    "#print(summary(model, (3, 320, 320), device='cpu'))\n",
    "\n",
    "# model = UNet3Plus(n_channels=3, n_classes=12)\n",
    "# print(summary(model, (3, 320, 320), device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleAttributeError",
     "evalue": "'EfficientNet' object has no attribute 'Conv2dStaticSamePadding'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-58533acb7992>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mConv2dStaticSamePadding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    777\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 779\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    780\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleAttributeError\u001b[0m: 'EfficientNet' object has no attribute 'Conv2dStaticSamePadding'"
     ]
    }
   ],
   "source": [
    "for i in range(len(model._blocks)):\n",
    "    print(model.Conv2dStaticSamePadding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModuleList(\n",
      "  (0): MBConvBlock(\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      48, 48, kernel_size=(3, 3), stride=[1, 1], groups=48, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(48, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      48, 12, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      12, 48, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      48, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (1): MBConvBlock(\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      24, 24, kernel_size=(3, 3), stride=(1, 1), groups=24, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      24, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      6, 24, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      24, 24, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(24, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (2): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      144, 144, kernel_size=(3, 3), stride=[2, 2], groups=144, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(144, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      144, 6, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      6, 144, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (3): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (4): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (5): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      192, 192, kernel_size=(3, 3), stride=(1, 1), groups=192, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(32, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (6): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      192, 192, kernel_size=(5, 5), stride=[2, 2], groups=192, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(192, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      192, 8, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      8, 192, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      192, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (7): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (8): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (9): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      336, 336, kernel_size=(5, 5), stride=(1, 1), groups=336, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      336, 56, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(56, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (10): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      56, 336, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      336, 336, kernel_size=(3, 3), stride=[2, 2], groups=336, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(0, 1, 0, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(336, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      336, 14, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      14, 336, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      336, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (11): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (12): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (13): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (14): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (15): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      672, 672, kernel_size=(3, 3), stride=(1, 1), groups=672, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(112, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (16): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      672, 672, kernel_size=(5, 5), stride=[1, 1], groups=672, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(672, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      672, 28, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      28, 672, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (17): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (18): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (19): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (20): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (21): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      960, 960, kernel_size=(5, 5), stride=(1, 1), groups=960, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(160, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (22): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      960, 960, kernel_size=(5, 5), stride=[2, 2], groups=960, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 2, 1, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(960, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      960, 40, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      40, 960, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      960, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (23): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (24): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (25): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (26): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (27): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (28): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (29): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(5, 5), stride=(1, 1), groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(2, 2, 2, 2), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 272, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(272, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (30): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      272, 1632, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      1632, 1632, kernel_size=(3, 3), stride=[1, 1], groups=1632, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(1632, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      1632, 68, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      68, 1632, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      1632, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      "  (31): MBConvBlock(\n",
      "    (_expand_conv): Conv2dStaticSamePadding(\n",
      "      448, 2688, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn0): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_depthwise_conv): Conv2dStaticSamePadding(\n",
      "      2688, 2688, kernel_size=(3, 3), stride=(1, 1), groups=2688, bias=False\n",
      "      (static_padding): ZeroPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "    )\n",
      "    (_bn1): BatchNorm2d(2688, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_se_reduce): Conv2dStaticSamePadding(\n",
      "      2688, 112, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_se_expand): Conv2dStaticSamePadding(\n",
      "      112, 2688, kernel_size=(1, 1), stride=(1, 1)\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_project_conv): Conv2dStaticSamePadding(\n",
      "      2688, 448, kernel_size=(1, 1), stride=(1, 1), bias=False\n",
      "      (static_padding): Identity()\n",
      "    )\n",
      "    (_bn2): BatchNorm2d(448, eps=0.001, momentum=0.010000000000000009, affine=True, track_running_stats=True)\n",
      "    (_swish): MemoryEfficientSwish()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model._blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train, validation, test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:11:51.990197Z",
     "start_time": "2021-04-29T13:11:51.978168Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(num_epochs, model, data_loader, val_loader, criterion, optimizer, saved_dir, val_every, device):\n",
    "    print('Start training..')\n",
    "    best_loss = 9999999\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "            \n",
    "            # gpu 연산을 위해 device 할당\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "                  \n",
    "            # inference\n",
    "            outputs = model(images)\n",
    "            \n",
    "            # loss 계산 (cross entropy loss)\n",
    "            loss = criterion(outputs, masks)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # step 주기에 따른 loss 출력\n",
    "            if (step + 1) % 25 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(\n",
    "                    epoch+1, num_epochs, step+1, len(train_loader), loss.item()))\n",
    "        \n",
    "        # validation 주기에 따른 loss 출력 및 best model 저장\n",
    "        if (epoch + 1) % val_every == 0:\n",
    "            avrg_loss = validation(epoch + 1, model, val_loader, criterion, device)\n",
    "            if avrg_loss < best_loss:\n",
    "                print('Best performance at epoch: {}'.format(epoch + 1))\n",
    "                print('Save model in', saved_dir)\n",
    "                best_loss = avrg_loss\n",
    "                save_model(model, saved_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:11:51.252774Z",
     "start_time": "2021-04-29T13:11:51.236775Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(epoch, model, data_loader, criterion, device):\n",
    "    print('Start validation #{}'.format(epoch))\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_loss = 0\n",
    "        cnt = 0\n",
    "        mIoU_list = []\n",
    "        for step, (images, masks, _) in enumerate(data_loader):\n",
    "            \n",
    "            images = torch.stack(images)       # (batch, channel, height, width)\n",
    "            masks = torch.stack(masks).long()  # (batch, channel, height, width)\n",
    "\n",
    "            images, masks = images.to(device), masks.to(device)            \n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            total_loss += loss\n",
    "            cnt += 1    \n",
    "            outputs = torch.argmax(outputs, dim=1).detach().cpu().numpy()\n",
    "\n",
    "            mIoU = label_accuracy_score(masks.detach().cpu().numpy(), outputs, n_class=12)[2]\n",
    "            mIoU_list.append(mIoU)\n",
    "            \n",
    "        avrg_loss = total_loss / cnt\n",
    "        print('Validation #{}  Average Loss: {:.4f}, mIoU: {:.4f}'.format(epoch, avrg_loss, np.mean(mIoU_list)))\n",
    "\n",
    "    return avrg_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 저장 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:11:53.776085Z",
     "start_time": "2021-04-29T13:11:53.765085Z"
    }
   },
   "outputs": [],
   "source": [
    "# 모델 저장 함수 정의\n",
    "val_every = 1 \n",
    "\n",
    "saved_dir = './saved'\n",
    "if not os.path.isdir(saved_dir):                                                           \n",
    "    os.mkdir(saved_dir)\n",
    "    \n",
    "def save_model(model, saved_dir, file_name='efficientnet_baseline.pt'):\n",
    "    check_point = {'net': model.state_dict()}\n",
    "    output_path = os.path.join(saved_dir, file_name)\n",
    "    torch.save(model.state_dict(), output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 모델 생성 및 Loss function, Optimizer 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:11:54.442511Z",
     "start_time": "2021-04-29T13:11:54.427509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss function 정의\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer 정의\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr = learning_rate, weight_decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:14:57.117927Z",
     "start_time": "2021-04-29T13:11:54.742321Z"
    }
   },
   "outputs": [],
   "source": [
    "train(num_epochs, model, train_loader, val_loader, criterion, optimizer, saved_dir, val_every, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 저장된 model 불러오기 (학습된 이후) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:19:34.586969Z",
     "start_time": "2021-04-29T13:19:34.423941Z"
    }
   },
   "outputs": [],
   "source": [
    "# best model 저장된 경로\n",
    "model_path = './saved/efficientnet_baseline.pt'\n",
    "\n",
    "# best model 불러오기\n",
    "checkpoint = torch.load(model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# 추론을 실행하기 전에는 반드시 설정 (batch normalization, dropout 를 평가 모드로 설정)\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:19:35.338946Z",
     "start_time": "2021-04-29T13:19:34.779941Z"
    }
   },
   "outputs": [],
   "source": [
    "# 첫번째 batch의 추론 결과 확인\n",
    "for imgs, image_infos in test_loader:\n",
    "    image_infos = image_infos\n",
    "    temp_images = imgs\n",
    "    \n",
    "    model.eval()\n",
    "    # inference\n",
    "    outs = model(torch.stack(temp_images).to(device))\n",
    "    oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "    \n",
    "    break\n",
    "\n",
    "i = 3\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 16))\n",
    "\n",
    "print('Shape of Original Image :', list(temp_images[i].shape))\n",
    "print('Shape of Predicted : ', list(oms[i].shape))\n",
    "print('Unique values, category of transformed mask : \\n', [{int(i),category_names[int(i)]} for i in list(np.unique(oms[i]))])\n",
    "\n",
    "# Original image\n",
    "ax1.imshow(temp_images[i].permute([1,2,0]))\n",
    "ax1.grid(False)\n",
    "ax1.set_title(\"Original image : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "# Predicted\n",
    "ax2.imshow(oms[i])\n",
    "ax2.grid(False)\n",
    "ax2.set_title(\"Predicted : {}\".format(image_infos[i]['file_name']), fontsize = 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission을 위한 test 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:19:45.881676Z",
     "start_time": "2021-04-29T13:19:45.871704Z"
    }
   },
   "outputs": [],
   "source": [
    "def test(model, data_loader, device):\n",
    "    size = 256\n",
    "    transform = A.Compose([A.Resize(256, 256)])\n",
    "    print('Start prediction.')\n",
    "    model.eval()\n",
    "    \n",
    "    file_name_list = []\n",
    "    preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for step, (imgs, image_infos) in enumerate(test_loader):\n",
    "\n",
    "            # inference (512 x 512)\n",
    "            outs = model(torch.stack(imgs).to(device))\n",
    "            oms = torch.argmax(outs, dim=1).detach().cpu().numpy()\n",
    "            \n",
    "            # resize (256 x 256)\n",
    "            temp_mask = []\n",
    "            for img, mask in zip(np.stack(imgs), oms):\n",
    "                transformed = transform(image=img, mask=mask)\n",
    "                mask = transformed['mask']\n",
    "                temp_mask.append(mask)\n",
    "\n",
    "            oms = np.array(temp_mask)\n",
    "            \n",
    "            oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "            preds_array = np.vstack((preds_array, oms))\n",
    "            \n",
    "            file_name_list.append([i['file_name'] for i in image_infos])\n",
    "    print(\"End prediction.\")\n",
    "    file_names = [y for x in file_name_list for y in x]\n",
    "    \n",
    "    return file_names, preds_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission.csv 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-04-29T13:22:10.201081Z",
     "start_time": "2021-04-29T13:19:48.116689Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.read_csv('./submission/sample_submission.csv', index_col=None)\n",
    "\n",
    "# test set에 대한 prediction\n",
    "file_names, preds = test(model, test_loader, device)\n",
    "\n",
    "# PredictionString 대입\n",
    "for file_name, string in zip(file_names, preds):\n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in string.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(\"./submission/efficientnet_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "297.281px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
